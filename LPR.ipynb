{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bff1229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a915147",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('Licplatesdetection_train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('Licplatesdetection_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d662efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('Licplatesrecognition_train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('Licplatesrecognition_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbf0ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotations = pd.read_csv('Licplatesdetection_train.csv')\n",
    "recognition_annotations = pd.read_csv('Licplatesrecognition_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0c13e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>276</td>\n",
       "      <td>94</td>\n",
       "      <td>326</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>311</td>\n",
       "      <td>395</td>\n",
       "      <td>344</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>406</td>\n",
       "      <td>263</td>\n",
       "      <td>450</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.jpg</td>\n",
       "      <td>283</td>\n",
       "      <td>363</td>\n",
       "      <td>315</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.jpg</td>\n",
       "      <td>139</td>\n",
       "      <td>42</td>\n",
       "      <td>280</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>95.jpg</td>\n",
       "      <td>426</td>\n",
       "      <td>34</td>\n",
       "      <td>508</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>96.jpg</td>\n",
       "      <td>356</td>\n",
       "      <td>378</td>\n",
       "      <td>457</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>97.jpg</td>\n",
       "      <td>229</td>\n",
       "      <td>149</td>\n",
       "      <td>283</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>98.jpg</td>\n",
       "      <td>272</td>\n",
       "      <td>252</td>\n",
       "      <td>300</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>53</td>\n",
       "      <td>503</td>\n",
       "      <td>217</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_id  ymin  xmin  ymax  xmax\n",
       "0      1.jpg   276    94   326   169\n",
       "1     10.jpg   311   395   344   444\n",
       "2    100.jpg   406   263   450   434\n",
       "3    101.jpg   283   363   315   494\n",
       "4    102.jpg   139    42   280   222\n",
       "..       ...   ...   ...   ...   ...\n",
       "895   95.jpg   426    34   508   140\n",
       "896   96.jpg   356   378   457   548\n",
       "897   97.jpg   229   149   283   217\n",
       "898   98.jpg   272   252   300   383\n",
       "899   99.jpg    53   503   217   569\n",
       "\n",
       "[900 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ebe744c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>117T3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>128T8086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>94T3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>133T6719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.jpg</td>\n",
       "      <td>68T5979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>95.jpg</td>\n",
       "      <td>39T8707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>96.jpg</td>\n",
       "      <td>92T589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>97.jpg</td>\n",
       "      <td>180T706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>98.jpg</td>\n",
       "      <td>87T7369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>159T8894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_id      text\n",
       "0      0.jpg  117T3989\n",
       "1      1.jpg  128T8086\n",
       "2     10.jpg   94T3458\n",
       "3    100.jpg  133T6719\n",
       "4    101.jpg   68T5979\n",
       "..       ...       ...\n",
       "895   95.jpg   39T8707\n",
       "896   96.jpg    92T589\n",
       "897   97.jpg   180T706\n",
       "898   98.jpg   87T7369\n",
       "899   99.jpg  159T8894\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognition_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4f1f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection annotations columns: Index(['img_id', 'ymin', 'xmin', 'ymax', 'xmax'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Detection annotations columns:\", detection_annotations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5efe882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition annotations columns: Index(['img_id', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Recognition annotations columns:\", recognition_annotations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1cad5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotations.columns = detection_annotations.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a877422",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_annotations.columns = recognition_annotations.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e86e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_image_dir = 'Licplatesdetection_train'\n",
    "recognition_image_dir = 'Licplatesrecognition_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ae0d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_column_detection = 'img_id'  \n",
    "filename_column_recognition = 'img_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d0d3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_image_paths = [os.path.join(detection_image_dir, img_id) for img_id in detection_annotations[filename_column_detection]]\n",
    "recognition_image_paths = [os.path.join(recognition_image_dir, img_id) for img_id in recognition_annotations[filename_column_recognition]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dbfbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)  # Read the image file\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR (OpenCV default) to RGB\n",
    "            images.append(img)  # Append the image to the list\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ec8c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_images = load_images(detection_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2b36179",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_images = load_images(recognition_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b751233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8477c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function to normalize and resize images\n",
    "def preprocess_image(image, target_size):\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3dbff7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to detection and recognition images\n",
    "detection_images = [preprocess_image(img, (224, 224)) for img in detection_images]\n",
    "recognition_images = [preprocess_image(img, (224, 224)) for img in recognition_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcffa31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split detection data\n",
    "detection_train_images, detection_test_images, detection_train_labels, detection_test_labels = train_test_split(\n",
    "    detection_images, detection_annotations[['xmin', 'ymin', 'xmax', 'ymax']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb26a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split recognition data\n",
    "recognition_train_images, recognition_test_images, recognition_train_labels, recognition_test_labels = train_test_split(\n",
    "    recognition_images, recognition_annotations['license_plate_text'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple CNN for detection\n",
    "detection_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4)  # Output: 4 coordinates (xmin, ymin, xmax, ymax)])\n",
    "\n",
    "detection_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "detection_model.summary()\n",
    "\n",
    "# Train the detection model\n",
    "detection_model.fit(np.array(detection_train_images), np.array(detection_train_labels), epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_license_plate(image, bbox):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "# Extract license plates from test images\n",
    "detected_plates = [extract_license_plate(img, bbox) for img, bbox in zip(detection_test_images, detection_model.predict(np.array(detection_test_images)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade70e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# Recognize text using Tesseract OCR\n",
    "recognized_texts = [pytesseract.image_to_string(cv2.cvtColor(plate, cv2.COLOR_RGB2GRAY)) for plate in detected_plates]\n",
    "\n",
    "# Clean the recognized texts\n",
    "recognized_texts = [text.strip() for text in recognized_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate detection model (IoU or similar metric)\n",
    "# Evaluate recognition model\n",
    "recognition_accuracy = accuracy_score(recognition_test_labels, recognized_texts)\n",
    "print(f'Recognition Model Accuracy: {recognition_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'img_id': recognition_annotations['img_id'], 'license_plate_text': recognized_texts})\n",
    "\n",
    "submission.to_csv(SampleSubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb01dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa525fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029c96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f9802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6e170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
